# -*- coding: utf-8 -*-
"""Student_Performance

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tm39edI7TM09SjNyzhkqbbUyr5-zdqph
"""

# ==========================================
# ðŸ“Œ Student Performance - Full ML Pipeline
# Preprocessing + Visualization + Classification
# ==========================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 1ï¸âƒ£ Load Dataset
df = pd.read_csv("Student_performance_10k.csv")

print("ðŸ”¸ First 5 Rows:")
print(df.head())

print("\nðŸ”¸ Dataset Info Before Cleaning:")
print(df.info())

print("\nðŸ”¸ Summary Stats Before Cleaning:")
print(df.describe(include='all'))

# 2ï¸âƒ£ Missing Values
print("\nðŸ”¸ Missing Values Before:")
print(df.isnull().sum())

for col in df.columns:
    if df[col].dtype in ['int64', 'float64']:
        df[col] = df[col].fillna(df[col].mean())
    else:
        df[col] = df[col].fillna(df[col].mode()[0])

print("\nðŸ”¸ Missing Values After:")
print(df.isnull().sum())

# 3ï¸âƒ£ Remove Duplicates
before = df.shape[0]
df = df.drop_duplicates()
after = df.shape[0]
print(f"\nðŸ”¸ Duplicates Removed: {before - after}")

# 4ï¸âƒ£ Outlier Handling (IQR method)
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
before_outliers = df.shape[0]

for col in numeric_cols:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    df = df[(df[col] >= lower) & (df[col] <= upper)]

after_outliers = df.shape[0]
print(f"\nðŸ”¸ Rows removed due to outliers: {before_outliers - after_outliers}")

# 5ï¸âƒ£ Categorical Encoding
cat_cols = df.select_dtypes(include=['object']).columns
le = LabelEncoder()

for col in cat_cols:
    df[col] = le.fit_transform(df[col])

print("\nðŸ”¸ Sample Encoded Data:")
print(df.head())

# 6ï¸âƒ£ Normalization
scaler = MinMaxScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

print("\nðŸ”¸ Normalized Data (First 5 Rows):")
print(df.head())

# 7ï¸âƒ£ Visualizations

# Correlation Heatmap
plt.figure(figsize=(8, 5))
sns.heatmap(df.corr(), cmap='coolwarm', annot=False)
plt.title("Correlation Heatmap")
plt.show()

# Target column (assuming last column is target)
target_col = df.columns[-1]

# Target Distribution
plt.figure(figsize=(6, 4))
sns.countplot(x=target_col, data=df)
plt.title(f"Target Variable Distribution: {target_col}")
plt.show()

# âœ… Customized Pairplot (clean & professional)
cols = df.columns[:5].tolist() + [target_col]  # first 5 features + target
sns.pairplot(df[cols], hue=target_col, palette='coolwarm', diag_kind='kde', plot_kws={'alpha': 0.6})
plt.suptitle("Pair Plot (Colored by Target Grade)", y=1.02)
plt.show()

# 8ï¸âƒ£ Classification (Decision Tree)

# Assuming target is the last column
X = df.iloc[:, :-1]   # features
y = df.iloc[:, -1]    # target

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

print("\nðŸ”¸ Training Data Shape:", X_train.shape)
print("ðŸ”¸ Testing Data Shape:", X_test.shape)

# Train Model
clf = DecisionTreeClassifier(criterion='gini', random_state=42)
clf.fit(X_train, y_train)

# Predict
y_pred = clf.predict(X_test)

# Evaluate
print("\nðŸ”¸ Accuracy:", accuracy_score(y_test, y_pred))
print("\nðŸ”¸ Classification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()